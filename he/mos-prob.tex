% !TeX root = mos-he.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\begin{center}
\textbf{\LARGE סקירה על הסתברות}
\end{center}
\addcontentsline{toc}{section}{\Large סקירה של הסתברות}

סעיף זה סוקר מושגים בהתסבתרות. אביא דוגמה של כל מושג עבור הטלת קוביה הונגת עם שישה משטחים. 

\textbf{ניסוי \L{\small (experiment)}}
מושג לא מוגדר כאשר הכוונה היא לפעולה שיש לה תוצאות אפשריות. מונח אחר היא trial?? הטלת קוביה היא ניסוי.

\textbf{תוצאה \L{\small (outcome)}} 
התוצאה של ניסוי. אם אתה מטיל קוביה אחת, תוצאה אפשרית היא 
$4$.

\textbf{מרחב מדגם \L{\small (sample space)}}
קבוצת כל התוצאות האפשריות של ניסוי. הקבוצה 
$S=\{1,2,3,4,5,6\}$
היא מרחב המדגם של הטלת קוביה.

\textbf{אירוע \L{\small (event)}}
תת-קבוצה של מרחב מדגם. תת-הקבוצה 
$e=\{2,4,6\}\subseteq S$
היא האירוע של הופעת מספר זוגי בהטלת קוביה.

\textbf{משתנה אקראי \L{\small (random variable)}}
פונקציה ממרחב המדגם למספרים (ממשיים). יהי 
$T$
מרחב המדגם של הטלת זוג קוביות:
\[
T=\{(a,b)| a,b\in \{1,2,3,4,5,6\} \}\,.
\]
הגדר משתנה אקראי 
$X$
כפונקציה
$X:T \mapsto \{2,3,\ldots,11,12\}$
שממפה תוצאות של הטלת זוג קוביות לסכום המספרים על הקוביות:
\begin{equation}\label{eq.sum}
X((a,b)) = a+b\,.
\end{equation}

\textbf{איחוד, חיתוך, משלים \L{\small (union, intersection, complement)}} 
אירועים הם קבוצות ולכן למושגים הללו יש את המשמעות הרגילה בתורת הקבוצות. יהי
$e_1=\{2,4,6\}$
ו-%
$e_2=\{1,2,3\}$. 
אזי:
\[
e_1 \cup e_2=\{1,2,3,4,6\}\quad e_1 \cap e_2=\{2\}\quad \overline{e_1} = S\setminus e_1=\{1,3,5\}\,.
\]
החיתוך הוא קבוצת המספרים הזוגיים מתוך שלושת האיברים הראשונים במרחב המדגם. המשלים הוא קבוצת המספרים האי-זוגיים מתוך מרחב המדגם.

\textbf{זרים \L{\small (mutually exclusive)}} 
שני אירועים או יותר זרים אם החיתוך שלהם הוא הקבוצה הריקה.
$e_1=\{2,4,6\}$
ו-%
$e_2=\{1,3,5\}$
זרים כי
$e_1 \cap e_2=\emptyset$,
כלומר, אין תוצאות שהן מספרים שהם גם זוגיים וגם אי-זוגיים.

\textbf{הסתברות \L{\small (probability)}}
הסתברות היא הגבול של התדירות היחסית של אירוע. יהי
$e$ 
אירוע ויהי
$n_e$
מספר הפעמים שהאירוע 
$e$
מתרחש ב-%
$n$
חזרות על הניסוי. 
$P(e)$,
ההסתברות של האירוע
$e$,
היא:
\[
P(e) = \lim_{n\rightarrow \infty} \frac{n_e}{n}\,.
\]
הגדרה זו היא בעייתית כי אנחנו לאממש יודעים שהגבול קיים. ההגדרה מוגדרת על "חזרות על הניסוי" אולם אנו רוצים להגדיר הסתברות ללא קשר לסדרה מסויימת של ניסויים.

הסתברות מודרנית מבוסס על קבוצה של שלוש אקסיומות. לא נפתח את התיאוריה, אולם החשיבות של שתיים מהאקסיומות ברורה:
\begin{eqn}
P(e) &\geq& 0\\
P(S) &=& 1\,.
\end{eqn}
אירוע מתרחשת עם התסתברות כלשהי או שהיא לא מתרחשת, ומרחב המדגם הוא לפי ההגדרה כל התוצאות האפשריות.

\textbf{חוק המספרים הגדולים}
מבטיח שהתפיסה האינטואיטיבית שלנו שהתסברות היא תדירות יחסית דומה מאוד למה שקורה כאשר ניסוי מתבצע פעמים רבות.

\textbf{התפלגות אחידה \L{\small (uniformly distributed)}} 
אם הסתברות של כל התוצאת במרחב שוות, להסתברות התפלגות אחידה. אם 
$S$
היא קבוצה סופית ולהסתברות שלה התפלגות אחידה אזי:
\[
P(e)=\frac{|e|}{|S|}\,.
\]
אם אתה מטיל קוביה
\textbf{הוגנת}
ההסתברות של התוצאות מתפלגת אחידה ולכן עבור
$e=\{2,4,6\}$:
\[
P(e) = \frac{|e|}{|S|} = \frac{|\{2,4,6\}|}{|\{1,2,3,4,5,6\}|}=\frac{1}{2}\,.
\]

\textbf{הסתברות מותנית \L{\small (conditional probability)}} 
יהי 
$e_1,e_2$
אירועים. 
$P(e_1 | e_2)$,
ההסתברות המותנית ש-%
$e_1$
מתרחש אם נתון ש-%
$e_2$
מתרחש, נתונה על ידי:
\[
P(e_1 | e_2) = \disfrac{P(e_1 \cap e_2)}{P(e_2)}\,.
\]
יהי 
$e_1=\{1,2,3\}$
האירוע שקוביה מראה מספר פחות או שווה ל-%
$3$
ויהי
$e_2=\{2,4,6\}$
האירוע שהקוביה מראה מספר זוגי. אזי:
\[
P(e_2 | e_1) = \disfrac{P(E_2 \cap E_1)}{P(e_1)}=\disfrac{P(\{2\})}{P(\{2,4,6\})}= \disfrac{1/6}{1/2}=\disfrac{1}{3}\,.
\]
זה מתקבל על דעת כי אם אתה יודע שמספר הוא פחות או שווה ל-%
$3$,
רק אחת משלושת התוצאה היא מספר זוגי.

\textbf{בלתי-תלוי \L{\small (independence)}}
שני אירועים בלתי-תלויים אם ההסתברות של החיתוך שלהם היא המכפלה של ההסתברויות הנפרדות:
\[
P(e_1 \cap e_2)=P(e_1)\,P(e_2)\,.
\]
במונחים של הסבתרות מותנית:
\[
P(e_1 | e_2)=\frac{P(e_1)\cap P(e_2)}{P(e_2)} = \frac{P(e_1)\,P(e_2)}{P(e_2)}=P(e_1)\,. 
\]
עבור אירועים בלתי-תלויים
$e_1,e_2$,
ידיעה של הההסתברות של
$e_2$
לא מספק מידע על ההסתברות של
$e_1$.
שלוש הטלות של קוביה הוגנת בלתי-תלויות ולכן ההסתברות שכולם מראות מספר זוגי היא
$\frac{1}{2}\cdot \frac{1}{2}\cdot \frac{1}{2}=\frac{1}{8}$. 

\textbf{ממוצע \L{\small (average)}}
תהי
$S=\{a_1,\ldots,a_n\}$
קבוצה של ערכים. אזי:
\[
\mathit{Average}(S)=\disfrac{\sum_{i=1}^{n} a_i}{n}\,.
\]
ממוצע מחושב מעל לקבוצה של ערכים אבל הממוצע לא חייב להיות איבר בקבוצה. אם יש
$1000$
בעיירה ולהם
$3426$
ילדים, הממוצע של מספר הילדים למשפחה היא
$3.426$
למרות שברור שאין משפחה עם
$3.426$
ילדים. אם אתה מטיל קוביה שש פעמים ומקבל את המספרים
$\{2,2,4,4,5,6\}$
הממוצע הוא:
\[
\frac{2+2+4+4+5+6}{6}=\frac{23}{6}\approx 3.8\,,
\]
שוב, לא איבר בקבוצה.

\textbf{תוחלת \L{\small (expectation)}}
התוחלת של משתנה אקראי היא סכום ההסתברויות של כל תוצאה כפול הערך של משתנה עבור אותה תוצאה. עבור קוביה הוגנת לכל תוצאה יש הסתברות זהה ולכן:
\[
E(\textrm{קוביה ערך})=1\cdot \frac{1}{6} + 2\cdot\frac{1}{6} + 3\cdot\frac{1}{6} + 4\cdot\frac{1}{6} + 5\cdot\frac{1}{6} + 6\cdot\frac{1}{6}=3.5\,.
\]
השתנה האקראי
$X$
ממשוואה%
~\ref{eq.sum}
ממפה את המספרים המופיעים על זוג קוביות לסכום המספרים. ההסתברות של כל זוג היא
$1/36$,
אבל לזוגות
$(2,5)$
ו-%
$(5,2)$
אותו סכום ולכן הם שייכים לאותה תוצאה. הערכים של המשתנה האקראי הם
$\{2,\ldots,12\}$
ומספר הדרכים לקבל כל אחד הם:
\[
\begin{array}{l|rrrrrrrrrrr}
\textrm{סכום} & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12\\\hline
\textrm{זוגות} & 1 & 2 & 3 & 4 & 5 & 6 & 5 & 4 & 3 & 2 & 1
\end{array}
\]
התוחלת היא הממוצע של ערכי המשתנה האקראי כפול 
\textbf{המשקל}
שהוא ההסתברות של כל תוצאה:
\[
E(\textrm{קוביות זוג סכום})=2\cdot \frac{1}{36} + 3\cdot \frac{2}{36} + 4\cdot \frac{3}{36} + 
\cdots + 10\cdot \frac{3}{36} + 11\cdot \frac{2}{36} + 12\cdot \frac{1}{36} = 7\,.
\]
עבור קבוצה שרירותית של אירועים
$\{e_1,\ldots,e_n\}$
התוחלת היא:
\[
E=\sum_{i=1}^{n} e_iP(e_i)\,.
\]

\textbf{ליניאריות של התוחלת \L{\small (linearity of expectation)}}\label{p.linearity}
התוחלת היא פונקציה ליניארית
$E(ae_1 + be_2) = aE(e_1) + bE(e_2)$
ועבור ביטויים ליניאריים שרירותיים:
\[
E\left(\sum_{i=1}^{n} a_ie_i\right)=\sum_{i=1}^{n} a_iE(e_i)\,.
\]
הוכחה אפשר למצוא ב-%
\L{\cite[Section~4.9]{ross}}.

\textbf{משתנה מסמן \L{\small (indicator variable)}}
יהי
$e$
אירוע שההסתברות שלה היא
$P(e)$.
הגדר
$I_e$,
משתנה מסמן עבור 
$e$,
כך
\L{\cite[Chapter~4, Example~3b]{ross}}:
\[
I_e=
\left\{
\begin{array}{ll}
1,\quad \textrm{מתרחש}\; e\;\textrm{אם}\\
0, \quad \textrm{מתרחש לא}\;e\;\textrm{אם}\,.
\end{array}
\right.
\]
מכאן
$E(I_e)=1\cdot P(e) + 0\cdot (1-P(e))=P(e)$.

\bigskip

\textbf{\large נוסחאות מתמטיות}

\textbf{משפט הבינום \L{\small (binomial theorem)}}
אם
$p$
היא ההסתברות של אירוע
$e$
אזי ההסתברות שהתוצאה של סדרה של 
$n$
ניסויים בלתי-תלויים היא
\textbf{בדיוק}
$k$
אירועים 
$e$
ניתנת על ידי
\textbf{המקדם הבינומי (\L{binomial coefficient})}:
\[
\dischoose{n}{k} p^k (1-p)^{n-k}\,.
\]
לפי משפט הבינום:
\[
(x+y)^n=\sum_{i=0}^{n} \dischoose{n}{i} x^i y^{n-i}\,.
\]
עבור
$p,1-p$
המשוואה היא
$(p+(1-p))^n=1$,
כפי שאפשר לצפות כי אחת התוצאות חייבת להתרחש.

\textbf{סכום סדרה הנדסית \L{\small (sum of a geometric series)}}
עבור
$0<r<1$:
\[
\sum_{i=0}^{n} r^i = \disfrac{1-r^{n+1}}{1-r},\quad\quad
\sum_{i=0}^{\infty} r^i = \disfrac{1}{1-r}\,.
\]

\textbf{סכום סדרה הרמונית \L{\small (sum of a harmonic series)}}\label{p.harmonic}
עבור 
$n$
מספר שלם חיובי, הסדרה ההרמונית היא:
\[
H_n=\sum_{k=1}^{n}\disfrac{1}{k}\approx \ln n + \frac{1}{2n} + \gamma\,,
\]
כאשר
$\gamma \approx 0.5772$
הוא
\textbf{הקבוע של \L{Euler} \L{(Euler's constant)}}.
כאשר
$n$
שואף לאינסוף הסדרה מתבדרת:
\[
\sum_{k=1}^{\infty}\disfrac{1}{k}=\infty\,,
\]
כי
$\ln n$
אינו חסום.

\textbf{הקירוב של \L{Stirling} \L{\small (Stirling's approximation)}}
קשה מאוד לחשב
$n!$ 
עבור 
$n$ 
גדול. נוח להשתמש באחת הנוסחאות של הקירוב של
\L{Stirling}:
\begin{eqn}
n! &\approx& \sqrt{2\pi n}\left(\disfrac{n}{e}\right)^n\\
\ln (n!) &\approx& n\ln n - n\\
\ln (n!)  &\approx& n\ln n - n + \frac{1}{6}\left(8n^3+4n^2+n+\frac{1}{30}\right)+\frac{1}{2}\ln\pi\,.
\end{eqn}

\medskip

\textbf{\large התפלגות הסתברותית רציפה\L{\large (Continuous probability distribution)}}\label{p.continuous}

התפלגויות הסתברות רציפות לא מופיעות לעתים קרובות בסבר אבל עבור קוראים עם הרקע המתאים אנו סורקים את המושגים הבסיסיים.

ניתן להגדיר הסתברויות מעל למשתנים אקראים רציפים.  
\textbf{פונקציית הסתברות צפיפות \L{\small (probability density function (PDF))}} $f(x): \mathcal{R}\rightarrow \mathcal{R}$
ממפה תוצאה 
$x$
לערך של הפונקציה וכך להגדיר:
\[
P(x) = f(x)\,.
\]
הסיבות למונח זו היא שההסתברות של ההופעה של כל מספר ממשי
\textbf{אחד}
היא אפס, ולכן הדרך הנכונה היא לתת הסתברויות לסביבות של נקודות.

\textbf{התפלגות הסתברות מצטברת \L{\small (cumulative probability distribution (CPD))}}
עבור הסביבה
$[-\infty,a]$
מתקבל על ידי אינטגרציה של ה-PDF:
\[
P(x<a) = \int_{-\infty}^{a} f(x)\, dx\,.
\]
זו גם 
$P(x\leq a)$
כי
$P(a)=0$.

כמו כל הסתברות,
$P(x)\geq 0$
לכל
$x$
ו-%
\[
\int_{-\infty}^{\infty} P(x)\, dx=\int_{-\infty}^{\infty} f(x)\, dx=1\,.
\]
אם ערכו של האיטגרל אינו
$1$
חייבים להשתמש 
\textbf{בקבוע נירמול \L{(normalization constant)}}.
אם 
PDF
מתפלגת אחידה בסביבה
$[a,b]$
אזי:
\[
P(a\leq x \leq b)=\int_{a}^{b} 1\, dx=(b-a)\,,
\]
ולכן חייבים להגדיר:
\[
P(a\leq x \leq b)=\disfrac{1}{b-a}\int_{a}^{b} 1\, dx=\disfrac{1}{b-a}\cdot (b-a)=1\,.
\]
ניתן לחשב את התוחלת על ידי אינטגרציה של ה-PDF
$f(x)$
כפול
$x$:
\[
E(x)=\int_{-\infty}^{\infty} xf(x)\, dx\,.
\]
ניתן לקבל את ה-PDF על ידי גזירה של ה-CPD:
\[
P(x<a)= \frac{d}{da}\mathit{CDP}(x<a)\,.
\]
